"""
Script d'entraÃ®nement du modÃ¨le Random Forest BAHRIA
EntraÃ®ne un classificateur pour prÃ©dire les arrÃªts biologiques
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import joblib
import json

# Configuration des couleurs BAHRIA
NAVY = '#041E42'
OCEAN = '#0EA5E9'

# Seed pour reproductibilitÃ©
np.random.seed(42)

print("ğŸš€ ENTRAÃNEMENT DU MODÃˆLE BAHRIA")
print("=" * 80)
print()

# 1. Chargement des donnÃ©es
print("ğŸ“ Chargement du dataset...")
df = pd.read_csv('bahria_dataset_5000.csv')
print(f"   âœ… {len(df)} Ã©chantillons chargÃ©s")
print()

# 2. PrÃ©paration des donnÃ©es
print("ğŸ”§ PrÃ©paration des donnÃ©es...")
# SÃ©parer features (X) et target (y)
# On retire 'species' et 'arret', on garde les 10 features numÃ©riques
feature_cols = ['avg_size_cm', 'avg_weight_g', 'size_maturity_ratio', 'month',
                'sst_current', 'sst_spawn_delta', 'upwelling_index',
                'cpue_recent', 'cpue_trend_2y_pct', 'months_to_repro']

X = df[feature_cols]
y = df['arret']

print(f"   Features : {X.shape[1]} variables")
print(f"   Target   : ArrÃªt biologique (0/1)")
print()

# 3. Split train/test stratifiÃ©
print("ğŸ“Š Split train/test (80/20, stratifiÃ©)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"   Train : {len(X_train)} Ã©chantillons")
print(f"   Test  : {len(X_test)} Ã©chantillons")
print()

# 4. EntraÃ®nement du modÃ¨le
print("ğŸŒ² EntraÃ®nement du Random Forest...")
model = RandomForestClassifier(
    n_estimators=200,
    max_depth=12,
    min_samples_leaf=5,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)
print("   âœ… ModÃ¨le entraÃ®nÃ©")
print()

# 5. Cross-validation
print("ğŸ”„ Validation croisÃ©e (5-fold)...")
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
print(f"   Scores CV : {cv_scores}")
print(f"   Moyenne   : {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
print()

# 6. Ã‰valuation sur le test set
print("ğŸ“ˆ Ã‰valuation sur le jeu de test...")
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"   Accuracy  : {accuracy:.4f}")
print(f"   Precision : {precision:.4f}")
print(f"   Recall    : {recall:.4f}")
print(f"   F1-Score  : {f1:.4f}")
print()

# Rapport de classification dÃ©taillÃ©
print("ğŸ“‹ Rapport de classification :")
print(classification_report(y_test, y_pred,
                          target_names=['Pas d\'arrÃªt', 'ArrÃªt recommandÃ©']))
print()

# Matrice de confusion
print("ğŸ”¢ Matrice de confusion :")
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(f"   VN={cm[0,0]}  FP={cm[0,1]}")
print(f"   FN={cm[1,0]}  VP={cm[1,1]}")
print()

# 7. Feature importance
print("â­ Importance des features...")
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=True)

print(feature_importance.to_string(index=False))
print()

# 8. Visualisation Feature Importance
print("ğŸ“Š GÃ©nÃ©ration du graphique d'importance des features...")
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'], feature_importance['importance'],
         color=[OCEAN if i % 2 == 0 else NAVY for i in range(len(feature_importance))])
plt.xlabel('Importance', fontsize=12, fontweight='bold')
plt.ylabel('Feature', fontsize=12, fontweight='bold')
plt.title('Importance des Features - ModÃ¨le BAHRIA RF', fontsize=14, fontweight='bold', color=NAVY)
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
print("   âœ… Graphique sauvegardÃ© : feature_importance.png")
print()

# 9. Sauvegarde du modÃ¨le
print("ğŸ’¾ Sauvegarde du modÃ¨le...")
joblib.dump(model, 'bahria_rf_v1.joblib')
print("   âœ… ModÃ¨le sauvegardÃ© : bahria_rf_v1.joblib")
print()

# 10. Sauvegarde des mÃ©triques
print("ğŸ“ Sauvegarde des mÃ©triques...")
metrics = {
    'accuracy': float(accuracy),
    'precision': float(precision),
    'recall': float(recall),
    'f1_score': float(f1),
    'cross_val_mean': float(cv_scores.mean()),
    'cross_val_std': float(cv_scores.std()),
    'confusion_matrix': cm.tolist(),
    'feature_importance': {
        row['feature']: float(row['importance'])
        for _, row in feature_importance.iterrows()
    },
    'model_params': {
        'n_estimators': 200,
        'max_depth': 12,
        'min_samples_leaf': 5,
        'class_weight': 'balanced'
    },
    'dataset_info': {
        'n_samples_total': len(df),
        'n_samples_train': len(X_train),
        'n_samples_test': len(X_test),
        'n_features': len(feature_cols)
    }
}

with open('model_metrics.json', 'w', encoding='utf-8') as f:
    json.dump(metrics, f, indent=2, ensure_ascii=False)

print("   âœ… MÃ©triques sauvegardÃ©es : model_metrics.json")
print()

print("=" * 80)
print("âœ… ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS !")
print()
print("Fichiers gÃ©nÃ©rÃ©s :")
print("  - bahria_rf_v1.joblib          (modÃ¨le entraÃ®nÃ©)")
print("  - model_metrics.json           (mÃ©triques dÃ©taillÃ©es)")
print("  - feature_importance.png       (graphique)")
print()
